{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!add-apt-repository -y ppa:jonathonf/ffmpeg-4\n",
        "!apt update\n",
        "!apt install -y ffmpeg\n",
        "\n",
        "!pip install datasets>=2.6.1\n",
        "!pip install git+https://github.com/huggingface/transformers\n",
        "!pip install librosa\n",
        "!pip install evaluate>=0.30\n",
        "!pip install jiwer"
      ],
      "metadata": {
        "id": "-lOMVWbtzkxI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ],
      "metadata": {
        "id": "5V0UYmaP0v1s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BQdST4q8zcar"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "from datasets import load_dataset, DatasetDict, Audio\n",
        "\n",
        "from transformers import WhisperFeatureExtractor, WhisperTokenizer\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "common_voice = DatasetDict()\n",
        "common_voice[\"train\"] = load_dataset(\"mozilla-foundation/common_voice_11_0\", \"sv-SE\", split=\"train+validation\", use_auth_token=True)\n",
        "common_voice[\"test\"] = load_dataset(\"mozilla-foundation/common_voice_11_0\", \"sv-SE\", split=\"test\", use_auth_token=True)\n",
        "common_voice = common_voice.remove_columns([\"accent\", \"age\", \"client_id\", \"down_votes\", \"gender\", \"locale\", \"path\", \"segment\", \"up_votes\"])\n",
        "\n",
        "feature_extractor = WhisperFeatureExtractor.from_pretrained(\"openai/whisper-small\")\n",
        "tokenizer = WhisperTokenizer.from_pretrained(\"openai/whisper-small\", language=\"Swedish\", task=\"transcribe\")\n",
        "\n",
        "common_voice = common_voice.cast_column(\"audio\", Audio(sampling_rate=16000))\n",
        "\n",
        "def prepare_dataset(batch):\n",
        "    # load and resample audio data from 48 to 16kHz\n",
        "    audio = batch[\"audio\"]\n",
        "\n",
        "    # compute log-Mel input features from input audio array \n",
        "    batch[\"input_features\"] = feature_extractor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).input_features[0]\n",
        "\n",
        "    # encode target text to label ids \n",
        "    batch[\"labels\"] = tokenizer(batch[\"sentence\"]).input_ids\n",
        "    return batch\n",
        "\n",
        "common_voice = common_voice.map(prepare_dataset, remove_columns=common_voice.column_names[\"train\"], num_proc=2)\n",
        "\n",
        "common_voice.save_to_disk(\"common_voice\")\n",
        "\n",
        "if not os.path.exists(\"/content/drive/My Drive/ID2223_lab2\"):\n",
        "    os.makedirs(\"/content/drive/My Drive/ID2223_lab2\")\n",
        "\n",
        "shutil.make_archive('/content/drive/My Drive/ID2223_lab2/common_voice', 'zip', 'common_voice')\n"
      ]
    }
  ]
}